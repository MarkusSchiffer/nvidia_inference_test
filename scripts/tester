#!/usr/bin/env python3

import numpy as np
from jetson_inference import depthNet
import jetson.utils
from PIL import Image

RGB_SOURCE = ""
DEPTH_SOURCE = ""
SEGMENTATION_SOURCE = ""

# load mono depth network
net = depthNet()

# load segmentation network

# depthNet re-uses the same memory for the depth field,
# so you only need to do this once (not every frame)
depth_field = net.GetDepthField()

# cudaToNumpy() will map the depth field cudaImage to numpy
# this mapping is persistent, so you only need to do it once
depth_numpy = jetson.utils.cudaToNumpy(depth_field)

print(f"depth field resolution is {depth_field.width}x{depth_field.height}, format={depth_field.format}")

net.Process(RGB_SOURCE)
jetson.utils.cudaDeviceSynchronize() # wait for GPU to finish processing, so we can use the results on CPU
	
# find the min/max values with numpy
min_depth = np.amin(depth_numpy)
max_depth = np.amax(depth_numpy)

im = Image.fromarray(depth_numpy)
im.save("depth.png")